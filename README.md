![Screenshot 2025-03-29 142941](https://github.com/user-attachments/assets/f004ef3f-260f-4028-9816-71846f94b607)
# naukri_auto_apply_bot
folder structure

Folder Structure Description
The naukri folder is structured to automate job search and application processes on Naukri using Python. It consists of several subfolders and files that handle different stages of data extraction, filtering, application, and status tracking. Below is a detailed breakdown:

📂 naukri
├── 📂 new_data
│ ├── 📄 final_search.py
│ │ - Extracts job data from Naukri.
│ │ - Collects details like job title, company, location, salary, job description, key skills, and other metadata.
│ │ - Saves the extracted data into a structured CSV file.
│ │
│ ├── 📄 review_rating.py
│ │ - Filters the extracted data based on:
│ │ - Company reviews
│ │ - Job ratings
│ │ - Listed companies
│ │ - Saves the filtered data into the filter folder.
│ │

├── 📂 filter
│ ├── 📄 data_apply.py
│ │ - Logs into the Naukri account.
│ │ - Opens filtered_data.csv (contains filtered job data).
│ │ - Applies to jobs and handles different application statuses:
│ │ - Apply on Company Site
│ │ - Apply Directly
│ │ - Already Applied
│ │ - Register/Login to Apply
│ │ - Saves the collected data into application_status.csv.
│ │
│ ├── 📄 list_company.py
│ │ - Extracts and saves unique company data into unique_companies.csv.
│ │

├── 📂 status
│ ├── 📄 status_filter.py
│ │ - Categorizes job data based on application status.
│ │ - Divides and organizes the data into separate files or categories based on the outcome of the application process.

Folder Structure and File Description (Detailed)
The naukri project is designed to automate the process of job searching and applying on Naukri using Python and Playwright. Each file in the folder structure serves a specific purpose, from extracting job data to filtering and applying to jobs, and tracking the status of applications. Below is a detailed description of each file and its role in the automation process:

📂 naukri
The root folder contains all files and subfolders necessary for data extraction, filtering, applying to jobs, and tracking application status.

📂 new_data
The new_data folder is responsible for data collection and initial filtering. It contains scripts that gather job data from Naukri and filter it based on specific criteria like reviews and ratings.

📄 final_search.py
Purpose:
This script is the core of the data extraction process. It connects to Naukri, searches for job listings based on predefined filters, and collects detailed job information.

Functions and Workflow:

Connects to Naukri – Uses Playwright to navigate to Naukri and log in (if necessary).

Search for Jobs – Automates job search using specific criteria like:

Job title

Location

Experience level

Salary range

Extract Data – Collects the following information from each job listing:

Job title

Company name

Location

Salary (if available)

Job description

Required skills

Job highlights (like early applicant status)

Job match score

Industry type, role category, employment type, education requirements

Save Data – Saves the extracted data into a CSV file in a structured format for further processing.

Importance:

This script is essential for gathering raw data from Naukri, which is the foundation for all subsequent steps (filtering, applying, and tracking).

📄 review_rating.py
Purpose:
This script filters the raw job data based on specific criteria such as company review, rating, and whether the company is on a preferred list.

Functions and Workflow:

Read Extracted Data – Opens the CSV file generated by final_search.py.

Filter by Criteria:

Minimum rating threshold (e.g., greater than 3.5)

Company review threshold

Listed or preferred companies

Save Filtered Data:

Saves the filtered data into filtered_data.csv inside the filter folder.

Importance:

Reduces the size of the dataset by removing irrelevant or low-quality job listings.

Ensures that the automation process applies to high-quality jobs only.

📂 filter
The filter folder handles the job application process and company data management. Once the data is filtered, the scripts here automate the actual job application and organize company information.

📄 data_apply.py
Purpose:
This script automates the process of applying to jobs based on the filtered data and handles different types of apply buttons.

Functions and Workflow:

Login to Naukri:

Uses Playwright to log in to the Naukri account securely.

Open Filtered Data:

Reads filtered_data.csv to access the list of jobs.

Apply to Jobs:

Handles four types of apply buttons:

Apply on Company Site – Redirects to the company site.

Apply Directly – Directly applies to the job.

Already Applied – Skips if already applied.

Register/Login to Apply – Skips if login is required.

Save Application Status:

Records the status of each application in application_status.csv with details like:

Success/failure

Type of apply button

Time of application

Additional comments (if any)

Importance:

This script is the core of the automation process – automating the actual job application process.

Saves time by applying to multiple jobs quickly and recording their outcomes.

📄 list_company.py
Purpose:
This script extracts unique company information from the job data and saves it separately for reference.

Functions and Workflow:

Read Filtered Data:

Reads the filtered job data from filtered_data.csv.

Extract Unique Companies:

Identifies unique company names and associated details.

Save to CSV:

Saves the unique company data to unique_companies.csv with fields like:

Company name

Location

Industry type

Number of job postings

Importance:

Helps identify high-frequency employers.

Allows better targeting of companies in future applications.

📂 status
The status folder manages application tracking and organizes job statuses based on application outcomes.

📄 status_filter.py
Purpose:
This script organizes and categorizes job applications based on their final status.

Functions and Workflow:

Read Application Data:

Reads data from application_status.csv.

Categorize by Status:

Divides data into categories based on:

Successfully applied

Already applied

Apply on company site

Login required

Creates separate reports for each status.

Save Data:

Saves the categorized data into separate files for better tracking and analysis.

Importance:

Provides a clear overview of which jobs were successfully applied to.

Helps analyze application success rates and patterns.

Importance of the Entire Folder Structure
✅ Data Extraction and Cleaning
final_search.py → Extracts structured job data from Naukri.

review_rating.py → Cleans and filters the data for higher quality listings.

✅ Automation of Application
data_apply.py → Automates the job application process.

list_company.py → Organizes and saves unique company details.

✅ Tracking and Reporting
status_filter.py → Provides insights into the success and failure of applications.

Workflow Overview
Data Collection:

final_search.py collects raw job data.

Data Filtering:

review_rating.py filters data for relevance.

Job Application:

data_apply.py handles the application process.

Data Organization:

list_company.py saves company information.

Status Tracking:

status_filter.py organizes and categorizes application status.

Why This Structure is Effective
Modular Approach: Each script handles a specific task, improving maintainability and scalability.

Separation of Concerns: Data extraction, filtering, applying, and tracking are handled independently.

Scalability: The system can be expanded to include more complex filtering or additional data points.

Automation Efficiency: Reduces manual work and increases the number of job applications processed.

Outcome
This setup creates a fully automated job search and application system that:
✔️ Extracts job data efficiently.
✔️ Filters for high-quality job listings.
✔️ Applies to jobs automatically.
✔️ Tracks and reports application outcomes.


Summary
final_search.py → Extracts all job data from Naukri.

review_rating.py → Filters data based on review and rating.

data_apply.py → Logs in, applies to jobs, and saves status.

list_company.py → Extracts and saves unique company data.

status_filter.py → Organizes data based on the status of applications.
